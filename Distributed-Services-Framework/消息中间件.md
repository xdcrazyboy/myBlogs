
# 消息中间件概述

## 消息队列常用的使用场景：

- **非实时性**：当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。主要解决了应用耦合、异步处理、流量削锋等问题。
- **应用耦合**：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败；（如：订单->库存）
- **异步处理**：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间；(点对多场景，广播场景(注册发短信，发邮件)等等)
- **限流削峰**：应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况；(根据服务承受度设置队列大小，超过了就返回活动结束了，咱们经常各大商城秒杀，心里还没有点B数吗)减少压力,避免服务挂掉。
- **消息驱动的系统**：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理；(分工处理(各自对应相应的队列)，灵活应用(收到就处理/定时处理))


消息队列是异步RPC的主要手段之一，有两种模式：
1. 点对点：每个消息只有一个消费者（Consumer），不可重复消费(一旦被消费，消息就不再在消息队列中)
2. 发布/订阅：类似微信公众号(Topic)被大伙(订阅者)订阅关注。分为pull/push的。一个是被动拉取，一个是主动推送。
   >- **pull**:主动权在于消费方，优点是按需消费,服务端不用记录是否推送等状态；缺点就是消息延迟。
   >- **push**：主动权就在服务方了，优点是实时性高，服务端可以统一管理来进行负载；缺点就是发送消息的状态是集中式管理，服务端负载过大。


# 对比选型（RabbitMQ、ActiveMQ、RocketMQ、Kafka、Redis/ZeroMQ）

## 实际开发中消息中间件选型基于几个方面：

- **功能**：看需要什么功能去选，每种中间件支持的功能有差别。功能很多，比如优先级队列、延迟队列、死信队列(放没有推送成功的)、消费模式(pull/push)、广播消费、消息回溯、消息堆积+持久化、消息追踪(链路条，方便定位)、消息过滤(根据规则过滤啊，不同类别消息发送到不同topic)、多协议支持(通用性)、跨语言支持(流行程度)、流量控制、消息顺序性、安全机制(身份认证，权限认证(读写))、消息幂等性、事务性消息等。
- **性能**：一般是指其吞吐量，性能和功能很多时候是相悖的，需要做出取舍。
- **高可靠、高可用**：
  - 可靠，主要在于消息的持久化(消息只要写入就一定会被消费，不会因为故障导致数据丢失)；
  - 可用，主要在于对外部服务的依赖性(像kafka依赖zookeeper)，依赖也分强依赖和弱依赖；本身的备份机制所带来的保障性(像主从复制这种备份啊，增加多个slave来加强保障同时也会存在资源浪费，大部分时候Slave可能是空闲的)。
- 运维：通常有审核评估、监控、报警提醒、容灾、扩容、升级部署等等，一方面看中间件支撑的维度，一方面就看结合自动化运维的难易度
- 社区力度及生态发展：这个好理解吧，使用开源框架最开始基本上愉快的奔跑，但时不时的总会掉坑里，能不能爬出来一方面看自身的实力，一方面就看社区的力度了
- 成本： 尽量贴合团队自身的技术栈体系，让一个C栈的团队去深挖zeroMQ总比scala编写kafka要容易的多

## 详细对比
### 应用方面：

- RabbitMQ,遵循AMQP协议，由内在高并发的erlanng语言开发，用在实时的对可靠性要求比较高的消息传递上。
- kafka它主要用于处理活跃的流式数据,大数据量的数据处理上。
### 架构模型方面：

- RabbitMQ遵循AMQP协议，RabbitMQ的broker由Exchange,Binding,queue组成，其中exchange和binding组成了消息的路由键；客户端Producer通过连接channel和server进行通信，Consumer从queue获取消息进行消费（长连接，queue有消息会推送到consumer端，consumer循环从输入流读取数据）。rabbitMQ以broker为中心；有消息的确认机制。
- kafka遵从一般的MQ结构，producer，broker，consumer，以consumer为中心，消息的消费信息保存的客户端consumer上，consumer根据消费的点，从broker上批量pull数据；无消息确认机制。
### 吞吐量：

- rabbitMQ在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。
- kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。
### 可用性方面：

- rabbitMQ支持miror(镜像)的queue，主queue失效，miror queue接管。
- kafka的broker支持主备模式。
### 集群负载均衡方面：

- rabbitMQ的负载均衡需要单独的loadbalancer进行支持。
- kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上。


# Kafka
## 介绍
官方定义：一个分布式流处理平台。

官方入门Demo：[Kafka Quickstart](https://kafka.apache.org/quickstart)

- LinkedIn开发的，一个高性能、分布式的消息系统，广泛用于日志收集、流式数据处理、在线和离线消息分发等场景。是一种高吞吐量的分布式发布订阅消息系统，以可水平扩展和高吞吐率而被广泛使用。
- 开发语言：Java、Scala


跟其他消息系统比较，它的不同之处在于：
- 它是一个分布式系统，易于向外扩展
- 它同时为发布和订阅提供高吞吐量
- 支持多订阅者，失败时能自动平衡消费者
- 消息的持久化

其他的消息系统、消息中间件：
- ActiveMQ
  >实现了JMS1.1规范的，面向消息的中间件，高效、可扩展、安全和稳定的企业级消息通信。 Java语言实现。发送失败后即可重试。
- RabbitMQ
  >Erlang开发的AMQP协议的开源实现。
- RocketMQ
  >阿里巴巴开源的分布式消息中间件，JMS、MQTT协议。Java语言。


**相关名词**：
- producer 消息生产者，向`Broker`发送消息的客户端
- consumer 消息消费者，从`Broker`读取消息的客户端，消费者 <= 消息的分区数量
- broker 消息中间件处理节点
- properties
- topic 主题，kafaka根据topic对消息进行分类
- Partition 分区
- ConsumerGroup 一条消息可以发送到多个不同的ConsumerGroup，每个consumer都属于一个特定的ConsummerGroup，但是一个ConsumerGroup中只能有一个Consumer能够消费该消息

## 优点和缺点
**优点：**

- 客户端语言丰富，支持java、.net、php、ruby、python、go等多种语言；
- 性能卓越，单机写入TPS约在百万条/秒，消息大小10个字节；
- 提供完全分布式架构, 并有replica机制, 拥有较高的可用性和可靠性, 理论上支持消息无限堆积；
- 支持批量操作；
- 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;
- 有优秀的第三方Kafka Web管理界面Kafka-Manager；
- 在日志领域比较成熟，被多家公司和多个开源项目使用；

**缺点：**

- Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长
- 使用短轮询方式，实时性取决于轮询间隔时间；
- 消费失败不支持重试；
- 支持消息顺序，但是一台代理宕机后，就会产生消息乱序；
- 社区更新较慢；
- 
## Quick Start

### 一、下载安装包：
下载 [版本2.12-2.2.0](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.2.0/kafka_2.12-2.2.0.tgz)；然后解压，进去文件夹。
   ```
   > tar -xzf kafka_2.12-2.2.0.tgz
   > cd kafka_2.12-2.2.0
   ```
### 二、启动服务器
- 先启动zookeeper
- 然后启动Kafka服务器.分别开两个命令行窗口
   ```
   > bin/zookeeper-server-start.sh config/zookeeper.properties
   > bin/kafka-server-start.sh config/server.properties

   ```
### 三、创建topic
- 创建一个名为“test”的topic，只包含一个分区，一个副本;
   ```
   > bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
   ```
- 运行list topic命令，就可以看到刚刚创建的topic：
  ```
   > bin/kafka-topics.sh --list --bootstrap-server localhost:9092
        > test
   ```
### 四、发送一些消息，启动一个消费者
- 新开第三个窗口
   
   Kafka附带一个命令行客户端，它将从文件或标准输入中获取输入，并将其作为消息发送到Kafka集群。默认情况下，每行将作为单独的消息发送。
   运行生产者，然后在控制台中键入一些消息以发送到服务器
   ```
   > bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
        This is a message!
        This is an another message!
   
   ```
- 启动一个消费者，新开第四个窗口
   ```
   //Kafka还有一个命令行使用者，它会将消息转储到标准输出。
   > bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
        This is a message
        This is another message

   ```
### 创建一个多代理cluster
1. 首先复制下配置文件
    ```
    > cp config/server.properties config/server-1.properties
    > cp config/server.properties config/server-2.properties
    ```
2. 然后编辑这些新文件并设置以下属性：
    ```
    config/server-1.properties:
        broker.id=1
        listeners=PLAINTEXT://:9093
        log.dirs=/tmp/kafka-logs-1
     
    config/server-2.properties:
        broker.id=2
        listeners=PLAINTEXT://:9094
        log.dirs=/tmp/kafka-logs-2
    ```
    > broker.id属性是群集中每个节点的唯一且永久的名称。我们必须覆盖端口和日志目录，因为我们在同一台机器上运行这些，并且我们希望让所有代理尝试在同一端口上注册或覆盖彼此的数据。
3. Zookeeper和单节点已经启动了，所以我们只需要启动两个新节点
    ```
    > bin/kafka-server-start.sh config/server-1.properties &
    > bin/kafka-server-start.sh config/server-2.properties &
    ```
4. 现在创建一个复制因子为3的新主题
    ```
    > bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 1 --topic my-replicated-topic
    ```
5. 现在有一个集群了，如果想知道代理正在做什么？要查看运行“describe topics”命令：
    ```
    > bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-replicated-topic
        Topic:my-replicated-topic	PartitionCount:1 ReplicationFactor:3	Configs:segment.bytes=1073741824
	    Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 0,2,1	Isr: 0,2,1
    ```
    >第一行给出了所有分区的摘要，每个附加行提供有关一个分区的信息。由于此主题只有一个分区，因此只有一行。
     - “leader”是负责给定分区的所有读写的节点。每个节点将成为随机选择的分区部分的领导者。
     - “replicas”是复制此分区日志的节点列表，无论它们是否为领导者，或者即使它们当前处于活动状态。
     - “isr”是“同步”复制品的集合。这是副本列表的子集，该列表当前处于活跃状态并且已经被领导者捕获。

    > 示例中，节点1是主题的唯一分区的领导者。
    > 我们可以在我们创建的原始主题上运行相同的命令，以查看它的位置：
    ```
    > bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test
    ```
    > 所以毫无疑问 - 原始主题没有副本，并且位于服务器0上，是我们创建它时群集中唯一的服务器。让我们向我们的新主题发布一些消息：
    ```
    > bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-topic
        my test message 1
        my test message 2
        ^C
    ```
6. 然后消费消息
    ```
    > bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic
    ```
    > 现在让我们测试一下容错性。代理1充当领导者所以让我们先kill它：
    ```
    > ps aux | grep server-1.properties
    > kill -9 进程pid
    ```
7. 领导已切换到其中一个关注者，节点1不再处于同步副本集中：
    ```
    > bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic my-replicated-topic
    ```
8. 但即使最初接受写入的领导者已经失败，这些消息仍可供消费：
    ```
    > bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic
        my test message 1
        my test message 2
        ^C
    ```
### 使用Kafka Connect去导入或导出数据
从控制台写入数据并将其写回控制台是一个方便的起点，但您可能希望使用其他来源的数据或将数据从Kafka导出到其他系统。

对于许多系统，您可以使用Kafka Connect导入或导出数据，而不是编写自定义集成代码。

Kafka Connect是Kafka附带的工具，可以向Kafka导入和导出数据。它是一个可扩展的工具，可以运行连接器，实现与外部系统交互的自定义​​逻辑。

在本快速入门中，我们将了解如何使用简单的连接器运行Kafka Connect，这些连接器将数据从文件导入Kafka主题并将数据从Kafka主题导出到文件。

1. 首先，我们首先创建一些种子数据来测试：
   ```
   > echo -e "foo\nbar" > test.txt
   ``` 
2. 接下来，我们将启动以独立模式运行的两个连接器，这意味着它们在单个本地专用进程中运行。
   >我们提供三个配置文件作为参数。第一个始终是Kafka Connect流程的配置，包含常见配置，例如要连接的Kafka代理和数据的序列化格式。其余配置文件均指定要创建的连接器。这些文件包括唯一的连接器名称，要实例化的连接器类以及连接器所需的任何其他配置。
   ```
    > bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
   ```
3. Kafka附带的这些示例配置文件使用您之前启动的默认本地群集配置并创建两个连接器：第一个是源连接器，它从输入文件读取行并生成每个Kafka主题，第二个是宿连接器从Kafka主题读取消息并将每个消息生成为输出文件中的一行。
    > 在启动期间，您将看到许多日志消息，包括一些指示正在实例化连接器的日志消息。一旦Kafka Connect进程启动，源连接器应该开始从test.txt读取行并生成主题connect-test，并且接收器连接器应该开始从主题connect-test读取消息并将它们写入文件测试.sink.txt。我们可以通过检查输出文件的内容来验证数据是否已通过整个管道传递
    ```
    > more test.sink.txt
    ```
4. 当前数据存储在Kafka主题connect-test中，因此我们还可以运行控制台使用者来查看主题中的数据（或使用自定义使用者代码来处理它）：
    ```
    > bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
    ```
5. 连接器继续处理数据，因此我们可以将数据添加到文件中，并看到它在管道中移动：
   ```
   > echo Another line>> test.txt
   ```

### 使用Kafka流去处理数据
1. Kafka Streams是一个客户端库，用于构建任务关键型实时应用程序和微服务，其中输入和/或输出数据存储在Kafka集群中。

2. Kafka Streams结合了在客户端编写和部署标准Java和Scala应用程序的简单性以及Kafka服务器端集群技术的优势，使这些应用程序具有高度可扩展性，弹性，容错性，分布式等等。


# ActiveMQ
## 介绍
基于java开发，是Apache出品的、采用Java语言编写的完全基于JMS1.1规范的面向消息的中间件，为应用程序提供高效的、可扩展的、稳定的和安全的企业级消息通信。

不过由于历史原因包袱太重，目前市场份额没有后面三种消息中间件多，其最新架构被命名为Apollo,(京东的消息中间件就是基于activeMQ开发的)

## 优点

- 跨平台(JAVA编写与平台无关有，ActiveMQ几乎可以运行在任何的JVM上)
- 可以用JDBC：可以将数据持久化到数据库
- 支持JMS ：支持JMS的统一接口;
- 支持自动重连；
- 有安全机制：支持基于shiro，jaas等多种安全配置机制，可以对Queue/Topic进行认证和授权
- 监控完善：拥有完善的监控，包括Web Console，JMX，Shell命令行，Jolokia的REST API；
- 界面友善：提供的Web Console可以满足大部分情况，还有很多第三方的组件可以使用，如hawtio；
## 缺点：

- 社区活跃度不及RabbitMQ高；
- 会出莫名其妙的问题，会丢失消息；
- 不适合用于上千个队列的应用场景；

# RabbitMQ
## 介绍
基于erlang开发，是采用Erlang语言实现的AMQP协议的消息中间件，最初起源于金融系统，用于在分布式系统中存储转发消息。RabbitMQ发展到今天，被越来越多的人认可，这和它在可靠性、可用性、扩展性、功能丰富等方面的卓越表现是分不开的。

## 优点：
- 由于erlang语言的特性，mq性能较好，高并发；
- 健壮、稳定、易用、跨平台、支持多种语言、文档齐全；
- 有消息确认机制和持久化机制，可靠性高；
- 高度可定制的路由；
- 管理界面较丰富，在互联网公司也有较大规模的应用；
- 社区活跃度高；
## 缺点：

- 尽管结合erlang语言本身的并发优势，性能较好，但是不利于做二次开发和维护；
- 实现了代理架构，意味着消息在发送到客户端之前可以在中央节点上排队。此特性使得RabbitMQ易于使用和部署，但是使得其运行速度较慢，因为中央节点增加了延迟，消息封装后也比较大；
- 需要学习比较复杂的接口和协议，学习和维护成本较高；
# RocketMQ
基于java开发（阿里消息中间件）
是阿里开源的消息中间件，目前已经捐献个Apache基金会，它是由Java语言开发的，具备高吞吐量、高可用性、适合大规模分布式系统应用等特点，经历过双11的洗礼，实力不容小觑。
优点：

单机支持 1 万以上持久化队列
RocketMQ 的所有消息都是持久化的，先写入系统 pagecache(页高速缓冲存储器)，然后刷盘，可以保证内存与磁盘都有一份数据，访问时，直接从内存读取。
模型简单，接口易用（JMS 的接口很多场合并不太实用）
性能非常好，可以大量堆积消息在broker(集群中包含一个或多个服务器，这些服务器被称为broker)中；
支持多种消费，包括集群消费、广播消费等。
各个环节分布式扩展设计，主从HA(高可用性集群)；
开发度较活跃，版本更新很快。
缺点：

支持的客户端语言不多，目前是java及c++，其中c++不成熟；
RocketMQ社区关注度及成熟度也不及前两者；
没有web管理界面，提供了一个CLI(命令行界面)管理工具带来查询、管理和诊断各种问题；
没有在 mq 核心中去实现JMS等接口；

# zeroMQ
基于C开发
号称史上最快的消息队列，基于C语言开发。ZeroMQ是一个消息处理队列库，可在多线程、多内核和主机之间弹性伸缩，虽然大多数时候我们习惯将其归入消息队列家族之中，但是其和前面的几款有着本质的区别，ZeroMQ本身就不是一个消息队列服务器，更像是一组底层网络通讯库，对原有的Socket API上加上一层封装而已。
优点：

号称最快的消息队列系统，尤其针对大吞吐量的需求场景
单独部署或集成到应用中使用，不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演了这个服务角色
能够实现高级/复杂的队列，但是开发人员需要自己组合多种技术框架
跨平台，多语言支持
可作为Socket通信库使用
缺点：

仅提供非持久性的队列，也就是说如果down机，数据将会丢失

# redis
Redis的PUB/SUB机制，即发布-订阅模式。利用的Redis的列表(lists)数据结构。比较好的使用模式是，生产者lpush消息，消费者brpop消息，并设定超时时间，可以减少redis的压力。只有在Redis宕机且数据没有持久化的情况下丢失数据，可以根据业务通过AOF和缩短持久化间隔来保证很高的可靠性，而且也可以通过多个client来提高消费速度。但相对于专业的消息队列来说，该方案消息的状态过于简单(没有状态)，且没有ack机制，消息取出后消费失败依赖于client记录日志或者重新push到队列里面。

redis不支持分组(这点很重要，在做负载均衡的时候劣势就体现出来)，不过可以完全当做一个轻量级的队列使用，但redis他爹做了disque，可以去试一试。